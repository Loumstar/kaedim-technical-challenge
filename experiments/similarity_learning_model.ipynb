{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Retrieval using Learnt Similarity ResNet-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.23.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.12.0+cu116)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.13.0+cu116)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.5.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.64.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.28.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install numpy torch torchvision matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())\n",
    "\n",
    "def denorm(x, channels=None, w=None ,h=None, resize=False):\n",
    "    x = unnormalize(x)\n",
    "    \n",
    "    if resize:\n",
    "        if channels is None or w is None or h is None:\n",
    "            print('Number of channels, width and height must be provided for resize.')\n",
    "        x = x.view(x.size(0), channels, w, h)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(),                        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapenet_dataset = datasets.ImageFolder(\"ShapeNetRendering/\", transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling and Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate dataset sizes: (107370.5, 27182.4, 1359.1)\n",
      "Dataset Lengths:\n",
      "\tTrain: 107371,\n",
      "\tTest: 27182,\n",
      "\tTrain 1359\n"
     ]
    }
   ],
   "source": [
    "ratios = (0.79, 0.2, 0.01)\n",
    "\n",
    "approximate_sizes = map(lambda x: round(len(shapenet_dataset) * x, 1), ratios)\n",
    "print(f\"Approximate dataset sizes: {tuple(approximate_sizes)}\")\n",
    "\n",
    "sizes = (107371, 27182, 1359)\n",
    "\n",
    "[train, test, query] = random_split(shapenet_dataset, sizes)\n",
    "\n",
    "print(f\"Dataset Lengths:\\n\\tTrain: {len(train)},\\n\\tTest: {len(test)},\\n\\tTrain {len(query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module): \n",
    "    def __init__(self, channels, stride=1): \n",
    "        super().__init__() \n",
    "        \n",
    "        self.in_channel, self.out_channel = channels\n",
    "\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channel, self.out_channel, kernel_size=3,\n",
    "                      stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.out_channel), \n",
    "            nn.ReLU(inplace=True), \n",
    "            nn.Conv2d(self.out_channel, self.out_channel, kernel_size=3,\n",
    "                      stride=1, padding=1, bias=False), \n",
    "            nn.BatchNorm2d(self.out_channel)\n",
    "        ) \n",
    "        \n",
    "        if stride != 1 or self.in_channel != self.out_channel: \n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channel, self.out_channel, kernel_size=1,\n",
    "                          stride=stride, padding=0, bias=False), \n",
    "                nn.BatchNorm2d(self.out_channel)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "            \n",
    "    def forward(self, x): \n",
    "        out = self.left(x) + self.shortcut(x)        \n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified ResNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedResNet18(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv2_x = nn.Sequential(\n",
    "            self.add_residual_layer((64, 64), 2, stride=1),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv3_x = self.add_residual_layer((64, 128), 2, stride=2)\n",
    "        self.conv4_x = self.add_residual_layer((128, 256), 2, stride=2)\n",
    "        self.conv5_x = self.add_residual_layer((256, 512), 2, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512, 1)\n",
    "        \n",
    "    def add_residual_layer(self, channels, num_blocks, stride):\n",
    "        channels_in, channels_out = channels\n",
    "        \n",
    "        layers = list()\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            if i == 0:\n",
    "                layer_stride = stride\n",
    "                layer_channels_in = channels_in\n",
    "            else:\n",
    "                layer_stride = 1\n",
    "                layer_channels_in = channels_out\n",
    "\n",
    "            layers.append(ResidualBlock(layer_channels_in,\n",
    "                                        channels_out, \n",
    "                                        layer_stride))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Hyperparameters \n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "\n",
    "# Additional Hyperparameters \n",
    "beta = 1\n",
    "image_size = 137\n",
    "weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar, beta):\n",
    "\tx_reshaped = x.view(-1, image_size ** 2)\n",
    "\trecon_x_reshaped = recon_x.view(-1, image_size ** 2)\n",
    "\n",
    "\tloss = F.mse_loss(recon_x_reshaped, x_reshaped, reduction=\"sum\")\n",
    "\tdivergence = torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / 2\n",
    "\n",
    "\treturn loss - (beta * divergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = VAEModel(latent_dim)\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate, \n",
    "                             weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, _ = next(iter(loader_test))\n",
    "\n",
    "print(f\"Dimensions of a batch: {samples.shape()}\")\n",
    "\n",
    "samples = samples.cpu()\n",
    "samples = make_grid(samples, nrow=8, padding=2, normalize=False,\n",
    "                    range=None, scale_each=False, pad_value=0)\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "plt.axis('off')\n",
    "\n",
    "show(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "epoch_losses = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tepoch_loss = 0\n",
    "\tnum_batches = 0\n",
    "\n",
    "\twith tqdm.tqdm(loader_train, unit=\"batch\") as tepoch: \n",
    "\t\tfor batch_idx, (data, _) in enumerate(tepoch):   \n",
    "\t\t\toptimiser.zero_grad()\n",
    "\t\t\tdata = data.to(device)\n",
    "\n",
    "\t\t\treconstruction, mu, logvar = model(data)\n",
    "\t\t\tloss = vae_loss(reconstruction, data, mu, logvar, beta)\n",
    "\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimiser.step()\n",
    "\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\t\tnum_batches += 1\n",
    "\n",
    "\t\t\tif batch_idx % 20 == 0:\n",
    "\t\t\t\ttepoch.set_description(f\"Epoch {epoch}\")\n",
    "\t\t\t\ttepoch.set_postfix(loss=loss.item()/len(data))\n",
    "\t\n",
    "\tepoch_losses.append(epoch_loss / num_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE Plot"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70ac0554d1fc8138b49fb10ebdd30b195d37745d25bc3607903881c8af422237"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
